import { Token } from "./Token.js";
import { Recognizer } from "./Recognizer.js";
import { RecognitionException } from "./RecognitionException.js";
import { LexerNoViableAltException } from "./LexerNoViableAltException.js";
import { LexerATNSimulator } from "./atn/LexerATNSimulator.js";
import { CharStream } from "./CharStream.js";
import { TokenFactory } from "./TokenFactory.js";
import { TokenSource } from "./TokenSource.js";
/**
 * A lexer is recognizer that draws input symbols from a character stream.
 * lexer grammars result in a subclass of this object. A Lexer object
 * uses simplified match() and error recovery mechanisms in the interest of speed.
 */
export declare abstract class Lexer extends Recognizer<LexerATNSimulator> implements TokenSource {
    static DEFAULT_MODE: number;
    static MORE: number;
    static SKIP: number;
    static DEFAULT_TOKEN_CHANNEL: number;
    static HIDDEN: number;
    static MIN_CHAR_VALUE: number;
    static MAX_CHAR_VALUE: number;
    _input: CharStream;
    /**
     * The goal of all lexer rules/methods is to create a token object.
     *  This is an instance variable as multiple rules may collaborate to
     *  create a single token.  nextToken will return this object after
     *  matching lexer rule(s).  If you subclass to allow multiple token
     *  emissions, then set this to the last token to be matched or
     *  something nonnull so that the auto token emit mechanism will not
     *  emit another token.
     */
    _token: Token | null;
    /**
     * What character index in the stream did the current token start at?
     *  Needed, for example, to get the text for current token.  Set at
     *  the start of nextToken.
     */
    _tokenStartCharIndex: number;
    /** The line on which the first character of the token resides */
    _tokenStartLine: number;
    /** The character position of first character within the line */
    _tokenStartColumn: number;
    /**
     * Once we see EOF on char stream, next token will be EOF.
     *  If you have DONE : EOF ; then you see DONE EOF.
     */
    _hitEOF: boolean;
    /** The channel number for the current token */
    _channel: number;
    /** The token type for the current token */
    _type: number;
    _modeStack: number[];
    _mode: number;
    /**
     * You can set the text for the current token to override what is in
     *  the input char buffer.  Use setText() or can set this instance var.
     */
    _text: string | null;
    protected _factory: TokenFactory<Token>;
    constructor(input: CharStream);
    reset(seekBack?: boolean): void;
    nextToken(): Token;
    /**
     * Instruct the lexer to skip creating a token for current lexer rule
     * and look for another token. nextToken() knows to keep looking when
     * a lexer rule finishes with token set to SKIP_TOKEN. Recall that
     * if token==null at end of any token rule, it creates one for you
     * and emits it.
     */
    skip(): void;
    more(): void;
    mode(m: number): void;
    pushMode(m: number): void;
    popMode(): number;
    /**
     * By default does not support multiple emits per nextToken invocation
     * for efficiency reasons. Subclass and override this method, nextToken,
     * and getToken (to push tokens into a list and pull from that list
     * rather than a single variable as this implementation does).
     */
    emitToken(token: Token): void;
    /**
     * The standard method called to automatically emit a token at the
     * outermost lexical rule. The token object should point into the
     * char buffer start..stop. If there is a text override in 'text',
     * use that to set the token's text. Override this method to emit
     * custom Token objects or provide a new factory.
     */
    emit(): Token;
    emitEOF(): Token;
    getCharIndex(): number;
    /**
     * Return a list of all Token objects in input char stream.
     * Forces load of all tokens. Does not include EOF token.
     */
    getAllTokens(): Token[];
    notifyListeners(e: LexerNoViableAltException): void;
    getErrorDisplay(s: string): string;
    getErrorDisplayForChar(c: string): string;
    getCharErrorDisplay(c: string): string;
    /**
     * Lexers can normally match any char in it's vocabulary after matching
     * a token, so do the easy thing and just kill a character and hope
     * it all works out. You can instead use the rule invocation stack
     * to do sophisticated error recovery if you are in a fragment rule.
     */
    recover(re: LexerNoViableAltException | RecognitionException): void;
    get inputStream(): CharStream;
    set inputStream(input: CharStream);
    set tokenFactory(factory: TokenFactory<Token>);
    get tokenFactory(): TokenFactory<Token>;
    get sourceName(): string;
    get type(): number;
    set type(type: number);
    get line(): number;
    set line(line: number);
    get column(): number;
    set column(column: number);
    get text(): string;
    set text(text: string | null);
}
